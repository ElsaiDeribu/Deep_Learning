{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "g0MjxHtxqo7h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dense Layer"
      ],
      "metadata": {
        "id": "7IpnrOkSssqS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Dense Layer class\n",
        "class DenseLayer:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        # Initialize weights and biases with small random values\n",
        "        self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "        self.biases = torch.zeros((1, n_neurons))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # Perform forward pass through the layer\n",
        "        self.output = torch.matmul(inputs, self.weights) + self.biases\n"
      ],
      "metadata": {
        "id": "TZK9r8I2ssR0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Functions"
      ],
      "metadata": {
        "id": "ckd0IvDLs1ZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define Activation classes\n",
        "class ActivationReLU:\n",
        "    def forward(self, inputs):\n",
        "        # Apply ReLU activation function element-wise\n",
        "        self.output = torch.max(torch.tensor(0), inputs)\n",
        "\n",
        "class ActivationSigmoid:\n",
        "    def forward(self, inputs):\n",
        "        # Apply Sigmoid activation function element-wise\n",
        "        self.output = 1 / (1 + torch.exp(inputs * -1))\n",
        "\n",
        "class ActivationSoftmax:\n",
        "    def forward(self, inputs):\n",
        "        # Apply Softmax activation function for probability distribution\n",
        "        exp_values = torch.exp(inputs - torch.max(inputs, axis=1, keepdim=True).values)\n",
        "        probabilities = exp_values / torch.sum(exp_values, axis=1, keepdim=True)\n",
        "        self.output = probabilities\n",
        "\n",
        "class LinearActivation:\n",
        "    def forward(self, x):\n",
        "        # Linear activation, no transformation\n",
        "        self.output = x\n"
      ],
      "metadata": {
        "id": "k9XNCt64qqve"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Neural Network Class with Training Functionality"
      ],
      "metadata": {
        "id": "FnHRPVPerNYm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xFuUqtasiiRM"
      },
      "outputs": [],
      "source": [
        "# Define the Neural Network class\n",
        "class NeuralNetwork:\n",
        "    def __init__(self):\n",
        "        # Initialize the neural network with a hidden layer, activation functions, and an output layer\n",
        "        self.hidden_layer = DenseLayer(2, 4)\n",
        "        self.activation1 = ActivationSigmoid()\n",
        "        self.output_layer = DenseLayer(4, 2)\n",
        "        self.activation2 = LinearActivation()\n",
        "\n",
        "    def forward_pass(self, X):\n",
        "        # Perform the forward pass through the neural network\n",
        "        self.hidden_layer.forward(X)\n",
        "        self.activation1.forward(self.hidden_layer.output)\n",
        "        self.output_layer.forward(self.activation1.output)\n",
        "        self.activation2.forward(self.output_layer.output)\n",
        "        return self.activation2.output\n",
        "\n",
        "    def backward_pass(self, y_pred, y_true):\n",
        "        # Set the learning rate\n",
        "        lr = torch.tensor(0.01)\n",
        "\n",
        "        # Calculate gradients and update weights and biases for the output layer\n",
        "        output_layer_gradients = y_pred - y_true\n",
        "        self.output_layer.weights -= lr * torch.mm(self.activation1.output.t(), output_layer_gradients)\n",
        "        self.output_layer.biases -= lr * torch.sum(output_layer_gradients, dim=0, keepdim=True)\n",
        "\n",
        "        # Calculate gradients and update weights and biases for the hidden layer\n",
        "        hidden_layer_gradients = torch.mm(output_layer_gradients, self.output_layer.weights.t()) * \\\n",
        "                                self.activation1.output * (1 - self.activation1.output)\n",
        "        self.hidden_layer.weights -= lr * torch.mm(X.view(1, -1).t(), hidden_layer_gradients)\n",
        "        self.hidden_layer.biases -= lr * torch.sum(hidden_layer_gradients, dim=0, keepdim=True)\n",
        "\n",
        "    def train(self, X, y, loss_threshold=0.00000001):\n",
        "        # Train the neural network using forward and backward passes until the loss reaches the threshold\n",
        "        y_pred = self.forward_pass(X)\n",
        "        err = self.error_calculation(y, y_pred)\n",
        "        print(\"Initial loss:\", err)\n",
        "        print(\"Initial prediction:\", y_pred)\n",
        "\n",
        "        while err > loss_threshold:\n",
        "            self.backward_pass(y_pred, y)\n",
        "            y_pred = self.forward_pass(X)\n",
        "            err = self.error_calculation(y, y_pred)\n",
        "\n",
        "        print(\"Final loss:\", err)\n",
        "        print(\"Final prediction:\", y_pred)\n",
        "        print(\"Target value:\", y)\n",
        "\n",
        "    def error_calculation(self, y_true, y_pred):\n",
        "        # Calculate the mean squared error between true and predicted values\n",
        "        return torch.mean(0.5 * (y_true - y_pred) ** 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Main Code - Neural Network Training"
      ],
      "metadata": {
        "id": "Z3v--PRPvy4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main code for training a neural network\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Define input data and target values\n",
        "    X = torch.tensor([0.1, 0.5])\n",
        "    y = torch.tensor([0.05, 0.95])\n",
        "\n",
        "    # Create an instance of the NeuralNetwork class\n",
        "    neural_network = NeuralNetwork()\n",
        "\n",
        "    # Train the neural network using the specified input and target values\n",
        "    neural_network.train(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhjxM2YorA8D",
        "outputId": "c57319cc-8445-48b7-be9d-4d9e1966279b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial loss: tensor(0.2216)\n",
            "Initial prediction: tensor([[0.0152, 0.0092]])\n",
            "Final loss: tensor(9.8431e-09)\n",
            "Final prediction: tensor([[0.0500, 0.9498]])\n",
            "Target value: tensor([0.0500, 0.9500])\n"
          ]
        }
      ]
    }
  ]
}